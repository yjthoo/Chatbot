{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9TCJcCscIUKk"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R1mxz7TuFhA1"
   },
   "outputs": [],
   "source": [
    "# import the datasets\n",
    "lines = open('cornell movie-dialogs corpus/movie_lines.txt', encoding='utf-8', \n",
    "             errors = \"ignore\").read().split(\"\\n\")\n",
    "conversations = open('cornell movie-dialogs corpus/movie_conversations.txt', \n",
    "                     encoding='utf-8', errors = \"ignore\").read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ecz_uuZtIMvm"
   },
   "outputs": [],
   "source": [
    "# Creating a dictionary that maps each line and its id\n",
    "id2line = {}\n",
    "for line in lines:\n",
    "    _line = line.split(' +++$+++ ')\n",
    "    if len(_line) == 5:\n",
    "        id2line[_line[0]] = _line[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rwF7KLKlIaLO"
   },
   "outputs": [],
   "source": [
    "# Creating a list of all of the conversations\n",
    "conversations_ids = []\n",
    "for conversation in conversations[:-1]:\n",
    "    _conversation = conversation.split(' +++$+++ ')[-1][1:-1].replace(\"'\", \"\").replace(\" \", \"\")\n",
    "    conversations_ids.append(_conversation.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RR6aykSmIda2"
   },
   "outputs": [],
   "source": [
    "# getting separately the questions and the answers\n",
    "rawQuestions = []\n",
    "rawAnswers = []\n",
    "\n",
    "for conversation in conversations_ids:\n",
    "    for i in range(len(conversation) - 1):\n",
    "        rawQuestions.append(id2line[conversation[i]])\n",
    "        rawAnswers.append(id2line[conversation[i+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yTB-TSgQIfdb"
   },
   "outputs": [],
   "source": [
    "# clean the texts\n",
    "def clean_text(text):\n",
    "    \n",
    "    contractions = {\n",
    "    \"ain't\": \"am not / are not\",\n",
    "    \"aren't\": \"are not / am not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"can't've\": \"cannot have\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"couldn't've\": \"could not have\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hadn't've\": \"had not have\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he had / he would\",\n",
    "    \"he'd've\": \"he would have\",\n",
    "    \"he'll\": \"he shall / he will\",\n",
    "    \"he'll've\": \"he shall have / he will have\",\n",
    "    \"he's\": \"he has / he is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'd'y\": \"how do you\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how has / how is\",\n",
    "    \"i'd\": \"I had / I would\",\n",
    "    \"i'd've\": \"I would have\",\n",
    "    \"i'll\": \"I shall / I will\",\n",
    "    \"i'll've\": \"I shall have / I will have\",\n",
    "    \"i'm\": \"I am\",\n",
    "    \"i've\": \"I have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'd\": \"it had / it would\",\n",
    "    \"it'd've\": \"it would have\",\n",
    "    \"it'll\": \"it shall / it will\",\n",
    "    \"it'll've\": \"it shall have / it will have\",\n",
    "    \"it's\": \"it has / it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mightn't've\": \"might not have\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"mustn't've\": \"must not have\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"needn't've\": \"need not have\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"oughtn't've\": \"ought not have\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"sha'n't\": \"shall not\",\n",
    "    \"shan't've\": \"shall not have\",\n",
    "    \"she'd\": \"she had / she would\",\n",
    "    \"she'd've\": \"she would have\",\n",
    "    \"she'll\": \"she shall / she will\",\n",
    "    \"she'll've\": \"she shall have / she will have\",\n",
    "    \"she's\": \"she has / she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"shouldn't've\": \"should not have\",\n",
    "    \"so've\": \"so have\",\n",
    "    \"so's\": \"so as / so is\",\n",
    "    \"that'd\": \"that would / that had\",\n",
    "    \"that'd've\": \"that would have\",\n",
    "    \"that's\": \"that has / that is\",\n",
    "    \"there'd\": \"there had / there would\",\n",
    "    \"there'd've\": \"there would have\",\n",
    "    \"there's\": \"there has / there is\",\n",
    "    \"they'd\": \"they had / they would\",\n",
    "    \"they'd've\": \"they would have\",\n",
    "    \"they'll\": \"they shall / they will\",\n",
    "    \"they'll've\": \"they shall have / they will have\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"to've\": \"to have\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we had / we would\",\n",
    "    \"we'd've\": \"we would have\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we'll've\": \"we will have\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what'll\": \"what shall / what will\",\n",
    "    \"what'll've\": \"what shall have / what will have\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what's\": \"what has / what is\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"when's\": \"when has / when is\",\n",
    "    \"when've\": \"when have\",\n",
    "    \"where'd\": \"where did\",\n",
    "    \"where's\": \"where has / where is\",\n",
    "    \"where've\": \"where have\",\n",
    "    \"who'll\": \"who shall / who will\",\n",
    "    \"who'll've\": \"who shall have / who will have\",\n",
    "    \"who's\": \"who has / who is\",\n",
    "    \"who've\": \"who have\",\n",
    "    \"why's\": \"why has / why is\",\n",
    "    \"why've\": \"why have\",\n",
    "    \"will've\": \"will have\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"won't've\": \"will not have\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"wouldn't've\": \"would not have\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"y'all'd\": \"you all would\",\n",
    "    \"y'all'd've\": \"you all would have\",\n",
    "    \"y'all're\": \"you all are\",\n",
    "    \"y'all've\": \"you all have\",\n",
    "    \"you'd\": \"you had / you would\",\n",
    "    \"you'd've\": \"you would have\",\n",
    "    \"you'll\": \"you shall / you will\",\n",
    "    \"you'll've\": \"you shall have / you will have\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\"\n",
    "    }\n",
    "    \n",
    "    text = text.lower()\n",
    "    for word in text.split():\n",
    "        if word in contractions:\n",
    "            text = text.replace(word, contractions[word])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pYco4UrDIjNv"
   },
   "outputs": [],
   "source": [
    "questions = []\n",
    "answers = []\n",
    "\n",
    "for question in rawQuestions:\n",
    "    questions.append(clean_text(question))\n",
    "    \n",
    "for answer in rawAnswers:\n",
    "    answers.append(clean_text(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nLPjm6GKIlXv"
   },
   "outputs": [],
   "source": [
    "# Filtering out the questions and answers that are too short or too long\n",
    "short_questions = []\n",
    "short_answers = []\n",
    "i = 0\n",
    "for question in questions:\n",
    "    if 2 <= len(question.split()) <= 25:\n",
    "        short_questions.append(question)\n",
    "        short_answers.append(answers[i])\n",
    "    i += 1\n",
    "questions = []\n",
    "answers = []\n",
    "i = 0\n",
    "for answer in short_answers:\n",
    "    if 2 <= len(answer.split()) <= 25:\n",
    "        answers.append(answer)\n",
    "        questions.append(short_questions[i])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r77RyW1lc3Ro"
   },
   "outputs": [],
   "source": [
    "def preprocess_sentence(w):\n",
    "\n",
    "  # creating a space between a word and the punctuation following it\n",
    "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "  w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "\n",
    "  w = w.strip()\n",
    "\n",
    "  # adding a start and an end token to the sentence\n",
    "  # so that the model know when to start and stop predicting.\n",
    "  w = '<start> ' + w + ' <end>'\n",
    "  return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AoqTXmP2Sehm"
   },
   "outputs": [],
   "source": [
    "def tokenize(questions, answers):\n",
    "\n",
    "  '''\n",
    "  fit a tokenizer on the text and pad the sequences\n",
    "  '''\n",
    "\n",
    "  tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=None, filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n', \n",
    "                                                    lower=False, split=\" \", char_level=False, oov_token=None, \n",
    "                                                    document_count=0)\n",
    "  text = questions.copy()\n",
    "  text.extend(answers)\n",
    "  tokenizer.fit_on_texts(text)\n",
    "\n",
    "  Qtensor = tokenizer.texts_to_sequences(questions)\n",
    "  Qtensor = tf.keras.preprocessing.sequence.pad_sequences(Qtensor, padding='post')\n",
    "\n",
    "  Atensor = tokenizer.texts_to_sequences(answers)\n",
    "  Atensor = tf.keras.preprocessing.sequence.pad_sequences(Atensor, padding='post')\n",
    "\n",
    "  return Qtensor, Atensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vQAP-KSvIB6E"
   },
   "outputs": [],
   "source": [
    "# sort the questions and answers by the length of the questions (speeds up the training by reducing padding)\n",
    "sorted_questions = []\n",
    "sorted_answers = []\n",
    "\n",
    "for questLen in range(1, 25 + 1):\n",
    "    for idx, quest in enumerate(questions):\n",
    "        if len(quest) == questLen:\n",
    "            sorted_questions.append(preprocess_sentence(questions[idx]))\n",
    "            sorted_answers.append(preprocess_sentence(answers[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9_RqVSaRzsNa"
   },
   "outputs": [],
   "source": [
    "num_examples = 1000\n",
    "\n",
    "input_tensor, target_tensor, tokenizer = tokenize(sorted_questions[:num_examples], sorted_answers[:num_examples])\n",
    "max_input_length, max_target_length = input_tensor.shape[1], input_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21301,
     "status": "ok",
     "timestamp": 1591542774398,
     "user": {
      "displayName": "Yong Joon Thoo",
      "photoUrl": "",
      "userId": "09654273073444808495"
     },
     "user_tz": -60
    },
    "id": "DKzuMEAzlGfm",
    "outputId": "759ac71b-0436-42ee-c985-5b6fa109aca8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4)\n",
      "(1000, 32)\n"
     ]
    }
   ],
   "source": [
    "print(input_tensor.shape)\n",
    "print(target_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hz9fQl6s2l_q"
   },
   "outputs": [],
   "source": [
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l0phpiYt0Zuu"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTMCell, Dense, Flatten, Dropout, StackedRNNCells, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wT2tuwJa23z_"
   },
   "outputs": [],
   "source": [
    "# setting the hyperparameters\n",
    "batch_size = 64\n",
    "lstm_units = 512\n",
    "num_layers = 3\n",
    "encoder_embedding_size = 512\n",
    "decoder_embedding_size = 512\n",
    "steps_per_epoch = len(input_tensor_train)//batch_size\n",
    "\n",
    "vocab_size = len(tokenizer.word_index)+1\n",
    "\n",
    "# dropout rate of 50% for hidden units\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ayktW_Db3C_x"
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(len(input_tensor_train))\n",
    "dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "dataset_val = tf.data.Dataset.from_tensor_slices((input_tensor_val, target_tensor_val)).shuffle(len(input_tensor_val))\n",
    "dataset_val = dataset_val.batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21178,
     "status": "ok",
     "timestamp": 1591542774412,
     "user": {
      "displayName": "Yong Joon Thoo",
      "photoUrl": "",
      "userId": "09654273073444808495"
     },
     "user_tz": -60
    },
    "id": "8pjnVl4qChEF",
    "outputId": "7c45fd42-4d0a-40fe-f358-6a836dc8f562"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 4]), TensorShape([64, 32]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fr_XNaWc3ydR"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, encoder_units, batch_size, keep_probability):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.batch_size = batch_size\n",
    "    self.encoder_units = encoder_units\n",
    "    self.keep_prob = keep_probability\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.lstm = tf.keras.layers.LSTM(self.encoder_units,\n",
    "                                     return_sequences=True,\n",
    "                                    return_state=True, dropout=0.5,\n",
    "                                     recurrent_initializer='glorot_uniform')\n",
    "    self.gru = tf.keras.layers.GRU(self.encoder_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.lstmb = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(self.encoder_units,\n",
    "                                                                        return_sequences=True,\n",
    "                                                                        return_state=True,\n",
    "                                                                        dropout=0.5, recurrent_initializer='glorot_uniform'))\n",
    "\n",
    "  def call(self, x, hidden):\n",
    "    # pass through embedding layer\n",
    "    x = self.embedding(x)\n",
    "\n",
    "    #output, forward_h, forward_c, backward_h, backward_c = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(encoder_embedding_size, dropout=0.5, return_state = True), merge_mode = 'concat')(x,  initial_state = hidden)\n",
    "    #encoder_states = [forward_h, forward_c, backward_h, backward_c]\n",
    "\n",
    "    output, forward_h, forward_c, backward_h, backward_c = self.lstmb(x,  initial_state = hidden)\n",
    "    encoder_states = tf.keras.layers.Concatenate()([forward_h, backward_h])\n",
    "\n",
    "    return output, encoder_states\n",
    "\n",
    "  '''\n",
    "  def initialize_hidden_state(self):\n",
    "    return tf.zeros((self.batch_size, self.encoder_units))\n",
    "  '''\n",
    "\n",
    "  def initialize_hidden_state(self):\n",
    "    init_state = [tf.zeros((self.batch_size, self.encoder_units)) for i in range(4)]\n",
    "    return init_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21075,
     "status": "ok",
     "timestamp": 1591542774417,
     "user": {
      "displayName": "Yong Joon Thoo",
      "photoUrl": "",
      "userId": "09654273073444808495"
     },
     "user_tz": -60
    },
    "id": "qvOH8lEsBBsW",
    "outputId": "a2fa87ce-12c9-400b-c979-78cf09d538c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 4, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_size, encoder_embedding_size, lstm_units, batch_size, keep_probability)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g1XpNathnnpc"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, units):\n",
    "    super(BahdanauAttention, self).__init__()\n",
    "    self.W1 = tf.keras.layers.Dense(units)\n",
    "    self.W2 = tf.keras.layers.Dense(units)\n",
    "    self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "  def call(self, query, values):\n",
    "    # query hidden state shape == (batch_size, hidden size)\n",
    "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "    # values shape == (batch_size, max_len, hidden size)\n",
    "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "    query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "    # score shape == (batch_size, max_length, 1)\n",
    "    # we get 1 at the last axis because we are applying score to self.V\n",
    "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "    score = self.V(tf.nn.tanh(\n",
    "        self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "    # attention_weights shape == (batch_size, max_length, 1)\n",
    "    attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "    # context_vector shape after sum == (batch_size, hidden_size)\n",
    "    context_vector = attention_weights * values\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "    return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21345,
     "status": "ok",
     "timestamp": 1591542774741,
     "user": {
      "displayName": "Yong Joon Thoo",
      "photoUrl": "",
      "userId": "09654273073444808495"
     },
     "user_tz": -60
    },
    "id": "kuciAjfZqf2d",
    "outputId": "4e312b24-6383-46f6-fef4-61fa12d8c63f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ScBCFFw7qiqJ"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, decoder_units, batch_size):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_size = batch_size\n",
    "    self.decoder_units = decoder_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.decoder_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.lstm = tf.keras.layers.LSTM(self.decoder_units,\n",
    "                                     return_sequences=True,\n",
    "                                    return_state=True, dropout=0.5,\n",
    "                                     recurrent_initializer='glorot_uniform')\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    # used for attention\n",
    "    self.attention = BahdanauAttention(self.decoder_units)\n",
    "\n",
    "  def call(self, x, hidden, encoder_output):\n",
    "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "    context_vector, attention_weights = self.attention(hidden, encoder_output)\n",
    "\n",
    "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "    x = self.embedding(x)\n",
    "\n",
    "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "    # passing the concatenated vector to the LSTM\n",
    "    output, state_h, state_c = self.lstm(x)\n",
    "    state = tf.keras.layers.Concatenate()([state_h, state_c])\n",
    "\n",
    "    # output shape == (batch_size * 1, hidden_size)\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "    # output shape == (batch_size, vocab)\n",
    "    x = self.fc(output)\n",
    "\n",
    "    return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21318,
     "status": "ok",
     "timestamp": 1591542774750,
     "user": {
      "displayName": "Yong Joon Thoo",
      "photoUrl": "",
      "userId": "09654273073444808495"
     },
     "user_tz": -60
    },
    "id": "t0y7pTk8jtuX",
    "outputId": "58fceed2-b11a-4296-d0a8-0d340f260af3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 1848)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_size, decoder_embedding_size, lstm_units, batch_size)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((batch_size, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QIkgh6I_wqC3"
   },
   "outputs": [],
   "source": [
    "#import tensorflow_addons as tfa\n",
    "\n",
    "input_shape = input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yx3PoKDJpX48"
   },
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.1\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=100,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred, input_shape, sequence_length=25):\n",
    "\n",
    "  #https://www.tensorflow.org/addons/api_docs/python/tfa/seq2seq/sequence_loss\n",
    "  #return tfa.seq2seq.sequence_loss(pred, real, tf.ones([input_shape[0], sequence_length]))\n",
    "\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)\n",
    "\n",
    "#gradients = optimizer.compute_gradients(loss_error)\n",
    "#clipped_gradients = [(tf.clip_by_value(grad_tensor, -5., 5.), grad_variable) for grad_tensor, grad_variable in gradients if grad_tensor is not None]\n",
    "#optimizer_gradient_clipping = optimizer.apply_gradients(clipped_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IEQ6YCpAxu3p"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tXRMByZrzIba"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inputs, targets, encoder_hidden):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    encoder_output, encoder_hidden = encoder(inputs, encoder_hidden)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    decoder_input = tf.expand_dims([tokenizer.word_index['<start>']] * batch_size, 1)\n",
    "\n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    for t in range(1, targets.shape[1]):\n",
    "      # passing enc_output to the decoder\n",
    "      predictions, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_output)\n",
    "\n",
    "      #print(targets[:, t].shape, predictions.shape, input_shape)\n",
    "      loss += loss_function(targets[:, t], predictions, input_shape)\n",
    "\n",
    "      # using teacher forcing\n",
    "      decoder_input = tf.expand_dims(targets[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targets.shape[1]))\n",
    "\n",
    "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "  #gradients = optimizer.get_gradients(loss, variables)\n",
    "  #clipped_gradients = [(tf.clip_by_value(grad_tensor, -5., 5.), grad_variable) for grad_tensor, grad_variable in gradients if grad_tensor is not None]\n",
    "  #optimizer_gradient_clipping = optimizer.apply_gradients(clipped_gradients)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e7Kc93QgKLOp"
   },
   "outputs": [],
   "source": [
    "def evaluate_validation(inputs, targets, encoder_hidden):\n",
    "  \n",
    "  loss = 0\n",
    "  encoder_output, encoder_hidden = encoder(inputs, encoder_hidden)\n",
    "  decoder_hidden = encoder_hidden\n",
    "  \n",
    "  decoder_input = tf.expand_dims([tokenizer.word_index['<start>']] * batch_size, 1)\n",
    "  \n",
    "  # Teacher forcing - feeding the target as the next input\n",
    "  for t in range(1, targets.shape[1]):\n",
    "    # passing enc_output to the decoder\n",
    "    predictions, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_output)\n",
    "    loss += loss_function(targets[:, t], predictions, input_shape)\n",
    "    \n",
    "    # using teacher forcing\n",
    "    decoder_input = tf.expand_dims(targets[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targets.shape[1]))\n",
    "\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13086,
     "status": "ok",
     "timestamp": 1591544443214,
     "user": {
      "displayName": "Yong Joon Thoo",
      "photoUrl": "",
      "userId": "09654273073444808495"
     },
     "user_tz": -60
    },
    "id": "5yqVv_lqzutc",
    "outputId": "6adfae52-49f8-4a38-f4f8-77172e5a4055"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 0\n",
    "batch_training_loss_check = 10\n",
    "batch_validation_loss_check = steps_per_epoch // 2 - 1\n",
    "\n",
    "# elements for early stopping\n",
    "list_validation_loss_error = []\n",
    "early_stopping_check = 0\n",
    "early_stopping_stop = 100\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "  enc_hidden = encoder.initialize_hidden_state()\n",
    "  total_train_loss = 0\n",
    "\n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    start = time.time()\n",
    "    batch_train_loss = train_step(inp, targ, enc_hidden)\n",
    "    total_train_loss += batch_train_loss\n",
    "    end = time.time()\n",
    "    batch_time = end - start\n",
    "\n",
    "    if batch % batch_training_loss_check == 0:\n",
    "      print('Epoch {}, Batch {}, Training Loss {:.3f}, Training Time on {} batches: {:.2f} s'.format(epoch + 1,\n",
    "                                                   batch, batch_train_loss.numpy(), batch_training_loss_check, \n",
    "                                                   batch_time*batch_training_loss_check))\n",
    "      \n",
    "    if batch % batch_validation_loss_check == 0 and batch > 0:\n",
    "      total_valid_loss = 0\n",
    "      start_val_time = time.time()\n",
    "\n",
    "      for (batch_val, (inp_val, targ_val)) in enumerate(dataset_val.take(len(input_tensor_val)//batch_size)):\n",
    "        total_valid_loss += evaluate_validation(inp_val, targ_val, enc_hidden)\n",
    "\n",
    "      ending_val_time = time.time()\n",
    "      val_time = ending_val_time - start_val_time\n",
    "\n",
    "      average_validation_loss = total_valid_loss / (len(input_tensor_val) / batch_size)\n",
    "      print(\"Avg Validation Loss Error: {:>6.3f}, Validation Time: {:.2f} s\".format(average_validation_loss, val_time))\n",
    "\n",
    "      # early stopping\n",
    "      list_validation_loss_error.append(average_validation_loss_error)\n",
    "      \n",
    "      if average_validation_loss_error <= min(list_validation_loss_error):\n",
    "        early_stopping_check = 0\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "      else:\n",
    "        early_stopping_check += 1\n",
    "        if early_stopping_check == early_stopping_stop:\n",
    "          break\n",
    "\n",
    "  print('Epoch {}, Training Loss {:.3f}, Avg Validation Loss {:.3f}\\n'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch, average_validation_loss))\n",
    "  \n",
    "  if early_stopping_check == early_stopping_stop:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yEJ0Tf6ZbPGb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x220e71f40a0>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint('training_checkpoints/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# saving\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# loading\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_preprocessing.text.Tokenizer at 0x220e7071eb0>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "  attention_plot = np.zeros((max_target_length, max_input_length))\n",
    "\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  inputs = [tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_input_length,\n",
    "                                                         padding='post')\n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "  result = ''\n",
    "\n",
    "  hidden = [tf.zeros((1, lstm_units)) for i in range(4)] #[tf.zeros((1, lstm_units))]\n",
    "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "  dec_hidden = enc_hidden\n",
    "  dec_input = tf.expand_dims([tokenizer.word_index['<start>']], 0)\n",
    "\n",
    "  for t in range(max_target_length):\n",
    "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                         dec_hidden,\n",
    "                                                         enc_out)\n",
    "\n",
    "    # storing the attention weights to plot later on\n",
    "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "    result += tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "    if tokenizer.index_word[predicted_id] == '<end>':\n",
    "      return result, sentence, attention_plot\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "  fig = plt.figure(figsize=(10,10))\n",
    "  ax = fig.add_subplot(1, 1, 1)\n",
    "  ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "  fontdict = {'fontsize': 14}\n",
    "\n",
    "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer(sentence):\n",
    "  result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "  print('Input: %s' % (sentence))\n",
    "  print('Answer: {}'.format(result))\n",
    "\n",
    "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOxZZ7crBSXYmTXIdP8VPUH",
   "collapsed_sections": [],
   "name": "chatbot_tf2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
