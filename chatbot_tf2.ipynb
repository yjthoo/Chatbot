{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"chatbot_tf2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOxZZ7crBSXYmTXIdP8VPUH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"9TCJcCscIUKk","colab_type":"code","colab":{}},"source":["# import libraries\n","import numpy as np\n","import re\n","import time\n","\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K707TgcHEAhW","colab_type":"code","outputId":"b3c226ac-5b2c-4428-8f42-7bf54a430a02","executionInfo":{"status":"ok","timestamp":1591542761541,"user_tz":-60,"elapsed":8821,"user":{"displayName":"Yong Joon Thoo","photoUrl":"","userId":"09654273073444808495"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["!wget http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip"],"execution_count":79,"outputs":[{"output_type":"stream","text":["--2020-06-07 15:12:36--  http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n","Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 132.236.207.20\n","Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.20|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 9916637 (9.5M) [application/zip]\n","Saving to: ‘cornell_movie_dialogs_corpus.zip.1’\n","\n","cornell_movie_dialo 100%[===================>]   9.46M  2.60MB/s    in 4.2s    \n","\n","2020-06-07 15:12:41 (2.24 MB/s) - ‘cornell_movie_dialogs_corpus.zip.1’ saved [9916637/9916637]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"p9jowXekFKJG","colab_type":"code","outputId":"f52eb2c1-8523-4031-cc62-e5817e682aba","executionInfo":{"status":"ok","timestamp":1591542764172,"user_tz":-60,"elapsed":11371,"user":{"displayName":"Yong Joon Thoo","photoUrl":"","userId":"09654273073444808495"}},"colab":{"base_uri":"https://localhost:8080/","height":67}},"source":["!ls"],"execution_count":80,"outputs":[{"output_type":"stream","text":["'cornell movie-dialogs corpus'\t      __MACOSX\n"," cornell_movie_dialogs_corpus.zip     sample_data\n"," cornell_movie_dialogs_corpus.zip.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Osydne-pFN8Y","colab_type":"code","colab":{}},"source":["import zipfile\n","with zipfile.ZipFile(\"cornell_movie_dialogs_corpus.zip\", 'r') as zip_ref:\n","    zip_ref.extractall()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wcwLiiDwFY87","colab_type":"code","outputId":"427df32c-df20-4422-b1e5-0beca2f01b57","executionInfo":{"status":"ok","timestamp":1591542767418,"user_tz":-60,"elapsed":14570,"user":{"displayName":"Yong Joon Thoo","photoUrl":"","userId":"09654273073444808495"}},"colab":{"base_uri":"https://localhost:8080/","height":67}},"source":["!ls"],"execution_count":82,"outputs":[{"output_type":"stream","text":["'cornell movie-dialogs corpus'\t      __MACOSX\n"," cornell_movie_dialogs_corpus.zip     sample_data\n"," cornell_movie_dialogs_corpus.zip.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"R1mxz7TuFhA1","colab_type":"code","colab":{}},"source":["# import the datasets\n","lines = open('cornell movie-dialogs corpus/movie_lines.txt', encoding='utf-8', \n","             errors = \"ignore\").read().split(\"\\n\")\n","conversations = open('cornell movie-dialogs corpus/movie_conversations.txt', \n","                     encoding='utf-8', errors = \"ignore\").read().split(\"\\n\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ecz_uuZtIMvm","colab_type":"code","colab":{}},"source":["# Creating a dictionary that maps each line and its id\n","id2line = {}\n","for line in lines:\n","    _line = line.split(' +++$+++ ')\n","    if len(_line) == 5:\n","        id2line[_line[0]] = _line[4]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rwF7KLKlIaLO","colab_type":"code","colab":{}},"source":["# Creating a list of all of the conversations\n","conversations_ids = []\n","for conversation in conversations[:-1]:\n","    _conversation = conversation.split(' +++$+++ ')[-1][1:-1].replace(\"'\", \"\").replace(\" \", \"\")\n","    conversations_ids.append(_conversation.split(','))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RR6aykSmIda2","colab_type":"code","colab":{}},"source":["# getting separately the questions and the answers\n","rawQuestions = []\n","rawAnswers = []\n","\n","for conversation in conversations_ids:\n","    for i in range(len(conversation) - 1):\n","        rawQuestions.append(id2line[conversation[i]])\n","        rawAnswers.append(id2line[conversation[i+1]])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yTB-TSgQIfdb","colab_type":"code","colab":{}},"source":["# clean the texts\n","def clean_text(text):\n","    \n","    contractions = {\n","    \"ain't\": \"am not / are not\",\n","    \"aren't\": \"are not / am not\",\n","    \"can't\": \"cannot\",\n","    \"can't've\": \"cannot have\",\n","    \"'cause\": \"because\",\n","    \"could've\": \"could have\",\n","    \"couldn't\": \"could not\",\n","    \"couldn't've\": \"could not have\",\n","    \"didn't\": \"did not\",\n","    \"doesn't\": \"does not\",\n","    \"don't\": \"do not\",\n","    \"hadn't\": \"had not\",\n","    \"hadn't've\": \"had not have\",\n","    \"hasn't\": \"has not\",\n","    \"haven't\": \"have not\",\n","    \"he'd\": \"he had / he would\",\n","    \"he'd've\": \"he would have\",\n","    \"he'll\": \"he shall / he will\",\n","    \"he'll've\": \"he shall have / he will have\",\n","    \"he's\": \"he has / he is\",\n","    \"how'd\": \"how did\",\n","    \"how'd'y\": \"how do you\",\n","    \"how'll\": \"how will\",\n","    \"how's\": \"how has / how is\",\n","    \"i'd\": \"I had / I would\",\n","    \"i'd've\": \"I would have\",\n","    \"i'll\": \"I shall / I will\",\n","    \"i'll've\": \"I shall have / I will have\",\n","    \"i'm\": \"I am\",\n","    \"i've\": \"I have\",\n","    \"isn't\": \"is not\",\n","    \"it'd\": \"it had / it would\",\n","    \"it'd've\": \"it would have\",\n","    \"it'll\": \"it shall / it will\",\n","    \"it'll've\": \"it shall have / it will have\",\n","    \"it's\": \"it has / it is\",\n","    \"let's\": \"let us\",\n","    \"ma'am\": \"madam\",\n","    \"mayn't\": \"may not\",\n","    \"might've\": \"might have\",\n","    \"mightn't\": \"might not\",\n","    \"mightn't've\": \"might not have\",\n","    \"must've\": \"must have\",\n","    \"mustn't\": \"must not\",\n","    \"mustn't've\": \"must not have\",\n","    \"needn't\": \"need not\",\n","    \"needn't've\": \"need not have\",\n","    \"o'clock\": \"of the clock\",\n","    \"oughtn't\": \"ought not\",\n","    \"oughtn't've\": \"ought not have\",\n","    \"shan't\": \"shall not\",\n","    \"sha'n't\": \"shall not\",\n","    \"shan't've\": \"shall not have\",\n","    \"she'd\": \"she had / she would\",\n","    \"she'd've\": \"she would have\",\n","    \"she'll\": \"she shall / she will\",\n","    \"she'll've\": \"she shall have / she will have\",\n","    \"she's\": \"she has / she is\",\n","    \"should've\": \"should have\",\n","    \"shouldn't\": \"should not\",\n","    \"shouldn't've\": \"should not have\",\n","    \"so've\": \"so have\",\n","    \"so's\": \"so as / so is\",\n","    \"that'd\": \"that would / that had\",\n","    \"that'd've\": \"that would have\",\n","    \"that's\": \"that has / that is\",\n","    \"there'd\": \"there had / there would\",\n","    \"there'd've\": \"there would have\",\n","    \"there's\": \"there has / there is\",\n","    \"they'd\": \"they had / they would\",\n","    \"they'd've\": \"they would have\",\n","    \"they'll\": \"they shall / they will\",\n","    \"they'll've\": \"they shall have / they will have\",\n","    \"they're\": \"they are\",\n","    \"they've\": \"they have\",\n","    \"to've\": \"to have\",\n","    \"wasn't\": \"was not\",\n","    \"we'd\": \"we had / we would\",\n","    \"we'd've\": \"we would have\",\n","    \"we'll\": \"we will\",\n","    \"we'll've\": \"we will have\",\n","    \"we're\": \"we are\",\n","    \"we've\": \"we have\",\n","    \"weren't\": \"were not\",\n","    \"what'll\": \"what shall / what will\",\n","    \"what'll've\": \"what shall have / what will have\",\n","    \"what're\": \"what are\",\n","    \"what's\": \"what has / what is\",\n","    \"what've\": \"what have\",\n","    \"when's\": \"when has / when is\",\n","    \"when've\": \"when have\",\n","    \"where'd\": \"where did\",\n","    \"where's\": \"where has / where is\",\n","    \"where've\": \"where have\",\n","    \"who'll\": \"who shall / who will\",\n","    \"who'll've\": \"who shall have / who will have\",\n","    \"who's\": \"who has / who is\",\n","    \"who've\": \"who have\",\n","    \"why's\": \"why has / why is\",\n","    \"why've\": \"why have\",\n","    \"will've\": \"will have\",\n","    \"won't\": \"will not\",\n","    \"won't've\": \"will not have\",\n","    \"would've\": \"would have\",\n","    \"wouldn't\": \"would not\",\n","    \"wouldn't've\": \"would not have\",\n","    \"y'all\": \"you all\",\n","    \"y'all'd\": \"you all would\",\n","    \"y'all'd've\": \"you all would have\",\n","    \"y'all're\": \"you all are\",\n","    \"y'all've\": \"you all have\",\n","    \"you'd\": \"you had / you would\",\n","    \"you'd've\": \"you would have\",\n","    \"you'll\": \"you shall / you will\",\n","    \"you'll've\": \"you shall have / you will have\",\n","    \"you're\": \"you are\",\n","    \"you've\": \"you have\"\n","    }\n","    \n","    text = text.lower()\n","    for word in text.split():\n","        if word in contractions:\n","            text = text.replace(word, contractions[word])\n","    \n","    return text"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pYco4UrDIjNv","colab_type":"code","colab":{}},"source":["questions = []\n","answers = []\n","\n","for question in rawQuestions:\n","    questions.append(clean_text(question))\n","    \n","for answer in rawAnswers:\n","    answers.append(clean_text(answer))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nLPjm6GKIlXv","colab_type":"code","colab":{}},"source":["# Filtering out the questions and answers that are too short or too long\n","short_questions = []\n","short_answers = []\n","i = 0\n","for question in questions:\n","    if 2 <= len(question.split()) <= 25:\n","        short_questions.append(question)\n","        short_answers.append(answers[i])\n","    i += 1\n","questions = []\n","answers = []\n","i = 0\n","for answer in short_answers:\n","    if 2 <= len(answer.split()) <= 25:\n","        answers.append(answer)\n","        questions.append(short_questions[i])\n","    i += 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r77RyW1lc3Ro","colab_type":"code","colab":{}},"source":["def preprocess_sentence(w):\n","\n","  # creating a space between a word and the punctuation following it\n","  # eg: \"he is a boy.\" => \"he is a boy .\"\n","  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n","  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n","  w = re.sub(r'[\" \"]+', \" \", w)\n","\n","  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n","  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n","\n","  w = w.strip()\n","\n","  # adding a start and an end token to the sentence\n","  # so that the model know when to start and stop predicting.\n","  w = '<start> ' + w + ' <end>'\n","  return w"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AoqTXmP2Sehm","colab_type":"code","colab":{}},"source":["def tokenize(questions, answers):\n","\n","  '''\n","  fit a tokenizer on the text and pad the sequences\n","  '''\n","\n","  tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=None, filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n', \n","                                                    lower=False, split=\" \", char_level=False, oov_token=None, \n","                                                    document_count=0)\n","  text = questions.copy()\n","  text.extend(answers)\n","  tokenizer.fit_on_texts(text)\n","\n","  Qtensor = tokenizer.texts_to_sequences(questions)\n","  Qtensor = tf.keras.preprocessing.sequence.pad_sequences(Qtensor, padding='post')\n","\n","  Atensor = tokenizer.texts_to_sequences(answers)\n","  Atensor = tf.keras.preprocessing.sequence.pad_sequences(Atensor, padding='post')\n","\n","  return Qtensor, Atensor, tokenizer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vQAP-KSvIB6E","colab_type":"code","colab":{}},"source":["# sort the questions and answers by the length of the questions (speeds up the training by reducing padding)\n","sorted_questions = []\n","sorted_answers = []\n","\n","for questLen in range(1, 25 + 1):\n","    for idx, quest in enumerate(questions):\n","        if len(quest) == questLen:\n","            sorted_questions.append(preprocess_sentence(questions[idx]))\n","            sorted_answers.append(preprocess_sentence(answers[idx]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9_RqVSaRzsNa","colab_type":"code","colab":{}},"source":["num_examples = 1000\n","\n","input_tensor, target_tensor, tokenizer = tokenize(sorted_questions[:num_examples], sorted_answers[:num_examples])\n","max_input_length, max_target_length = input_tensor.shape[1], input_tensor.shape[1]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKzuMEAzlGfm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"outputId":"759ac71b-0436-42ee-c985-5b6fa109aca8","executionInfo":{"status":"ok","timestamp":1591542774398,"user_tz":-60,"elapsed":21301,"user":{"displayName":"Yong Joon Thoo","photoUrl":"","userId":"09654273073444808495"}}},"source":["print(input_tensor.shape)\n","print(target_tensor.shape)"],"execution_count":94,"outputs":[{"output_type":"stream","text":["(1000, 4)\n","(1000, 32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Hz9fQl6s2l_q","colab_type":"code","colab":{}},"source":["input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"l0phpiYt0Zuu","colab_type":"code","colab":{}},"source":["from tensorflow.keras.layers import Input, LSTMCell, Dense, Flatten, Dropout, StackedRNNCells, Bidirectional\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import SGD, Adam"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wT2tuwJa23z_","colab_type":"code","colab":{}},"source":["# setting the hyperparameters\n","batch_size = 64\n","lstm_units = 512\n","num_layers = 3\n","encoder_embedding_size = 512\n","decoder_embedding_size = 512\n","steps_per_epoch = len(input_tensor_train)//batch_size\n","\n","vocab_size = len(tokenizer.word_index)+1\n","\n","# dropout rate of 50% for hidden units\n","keep_probability = 0.5"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ayktW_Db3C_x","colab_type":"code","colab":{}},"source":["dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(len(input_tensor_train))\n","dataset = dataset.batch(batch_size, drop_remainder=True)\n","\n","dataset_val = tf.data.Dataset.from_tensor_slices((input_tensor_val, target_tensor_val)).shuffle(len(input_tensor_val))\n","dataset_val = dataset_val.batch(batch_size, drop_remainder=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8pjnVl4qChEF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"7c45fd42-4d0a-40fe-f358-6a836dc8f562","executionInfo":{"status":"ok","timestamp":1591542774412,"user_tz":-60,"elapsed":21178,"user":{"displayName":"Yong Joon Thoo","photoUrl":"","userId":"09654273073444808495"}}},"source":["example_input_batch, example_target_batch = next(iter(dataset))\n","example_input_batch.shape, example_target_batch.shape"],"execution_count":99,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(TensorShape([64, 4]), TensorShape([64, 32]))"]},"metadata":{"tags":[]},"execution_count":99}]},{"cell_type":"code","metadata":{"id":"fr_XNaWc3ydR","colab_type":"code","colab":{}},"source":["class Encoder(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim, encoder_units, batch_size, keep_probability):\n","    super(Encoder, self).__init__()\n","    self.batch_size = batch_size\n","    self.encoder_units = encoder_units\n","    self.keep_prob = keep_probability\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","    self.lstm = tf.keras.layers.LSTM(self.encoder_units,\n","                                     return_sequences=True,\n","                                    return_state=True, dropout=0.5,\n","                                     recurrent_initializer='glorot_uniform')\n","    self.gru = tf.keras.layers.GRU(self.encoder_units,\n","                                   return_sequences=True,\n","                                   return_state=True,\n","                                   recurrent_initializer='glorot_uniform')\n","    self.lstmb = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(self.encoder_units,\n","                                                                        return_sequences=True,\n","                                                                        return_state=True,\n","                                                                        dropout=0.5, recurrent_initializer='glorot_uniform'))\n","\n","  def call(self, x, hidden):\n","    # pass through embedding layer\n","    x = self.embedding(x)\n","\n","    #output, forward_h, forward_c, backward_h, backward_c = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(encoder_embedding_size, dropout=0.5, return_state = True), merge_mode = 'concat')(x,  initial_state = hidden)\n","    #encoder_states = [forward_h, forward_c, backward_h, backward_c]\n","\n","    output, forward_h, forward_c, backward_h, backward_c = self.lstmb(x,  initial_state = hidden)\n","    encoder_states = tf.keras.layers.Concatenate()([forward_h, backward_h])\n","\n","    return output, encoder_states\n","\n","  '''\n","  def initialize_hidden_state(self):\n","    return tf.zeros((self.batch_size, self.encoder_units))\n","  '''\n","\n","  def initialize_hidden_state(self):\n","    init_state = [tf.zeros((self.batch_size, self.encoder_units)) for i in range(4)]\n","    return init_state"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qvOH8lEsBBsW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"outputId":"a2fa87ce-12c9-400b-c979-78cf09d538c9","executionInfo":{"status":"ok","timestamp":1591542774417,"user_tz":-60,"elapsed":21075,"user":{"displayName":"Yong Joon Thoo","photoUrl":"","userId":"09654273073444808495"}}},"source":["encoder = Encoder(vocab_size, encoder_embedding_size, lstm_units, batch_size, keep_probability)\n","\n","# sample input\n","sample_hidden = encoder.initialize_hidden_state()\n","sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n","print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n","print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"],"execution_count":101,"outputs":[{"output_type":"stream","text":["Encoder output shape: (batch size, sequence length, units) (64, 4, 1024)\n","Encoder Hidden state shape: (batch size, units) (64, 1024)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"g1XpNathnnpc","colab_type":"code","colab":{}},"source":["class BahdanauAttention(tf.keras.layers.Layer):\n","  def __init__(self, units):\n","    super(BahdanauAttention, self).__init__()\n","    self.W1 = tf.keras.layers.Dense(units)\n","    self.W2 = tf.keras.layers.Dense(units)\n","    self.V = tf.keras.layers.Dense(1)\n","\n","  def call(self, query, values):\n","    # query hidden state shape == (batch_size, hidden size)\n","    # query_with_time_axis shape == (batch_size, 1, hidden size)\n","    # values shape == (batch_size, max_len, hidden size)\n","    # we are doing this to broadcast addition along the time axis to calculate the score\n","    query_with_time_axis = tf.expand_dims(query, 1)\n","\n","    # score shape == (batch_size, max_length, 1)\n","    # we get 1 at the last axis because we are applying score to self.V\n","    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n","    score = self.V(tf.nn.tanh(\n","        self.W1(query_with_time_axis) + self.W2(values)))\n","\n","    # attention_weights shape == (batch_size, max_length, 1)\n","    attention_weights = tf.nn.softmax(score, axis=1)\n","\n","    # context_vector shape after sum == (batch_size, hidden_size)\n","    context_vector = attention_weights * values\n","    context_vector = tf.reduce_sum(context_vector, axis=1)\n","\n","    return context_vector, attention_weights"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kuciAjfZqf2d","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"outputId":"4e312b24-6383-46f6-fef4-61fa12d8c63f","executionInfo":{"status":"ok","timestamp":1591542774741,"user_tz":-60,"elapsed":21345,"user":{"displayName":"Yong Joon Thoo","photoUrl":"","userId":"09654273073444808495"}}},"source":["attention_layer = BahdanauAttention(10)\n","attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n","\n","print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n","print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"],"execution_count":103,"outputs":[{"output_type":"stream","text":["Attention result shape: (batch size, units) (64, 1024)\n","Attention weights shape: (batch_size, sequence_length, 1) (64, 4, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ScBCFFw7qiqJ","colab_type":"code","colab":{}},"source":["class Decoder(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim, decoder_units, batch_size):\n","    super(Decoder, self).__init__()\n","    self.batch_size = batch_size\n","    self.decoder_units = decoder_units\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","    self.gru = tf.keras.layers.GRU(self.decoder_units,\n","                                   return_sequences=True,\n","                                   return_state=True,\n","                                   recurrent_initializer='glorot_uniform')\n","    self.lstm = tf.keras.layers.LSTM(self.decoder_units,\n","                                     return_sequences=True,\n","                                    return_state=True, dropout=0.5,\n","                                     recurrent_initializer='glorot_uniform')\n","    self.fc = tf.keras.layers.Dense(vocab_size)\n","\n","    # used for attention\n","    self.attention = BahdanauAttention(self.decoder_units)\n","\n","  def call(self, x, hidden, encoder_output):\n","    # enc_output shape == (batch_size, max_length, hidden_size)\n","    context_vector, attention_weights = self.attention(hidden, encoder_output)\n","\n","    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n","    x = self.embedding(x)\n","\n","    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n","    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n","\n","    # passing the concatenated vector to the LSTM\n","    output, state_h, state_c = self.lstm(x)\n","    state = tf.keras.layers.Concatenate()([state_h, state_c])\n","\n","    # output shape == (batch_size * 1, hidden_size)\n","    output = tf.reshape(output, (-1, output.shape[2]))\n","\n","    # output shape == (batch_size, vocab)\n","    x = self.fc(output)\n","\n","    return x, state, attention_weights"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t0y7pTk8jtuX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"58fceed2-b11a-4296-d0a8-0d340f260af3","executionInfo":{"status":"ok","timestamp":1591542774750,"user_tz":-60,"elapsed":21318,"user":{"displayName":"Yong Joon Thoo","photoUrl":"","userId":"09654273073444808495"}}},"source":["decoder = Decoder(vocab_size, decoder_embedding_size, lstm_units, batch_size)\n","\n","sample_decoder_output, _, _ = decoder(tf.random.uniform((batch_size, 1)),\n","                                      sample_hidden, sample_output)\n","\n","print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"],"execution_count":105,"outputs":[{"output_type":"stream","text":["Decoder output shape: (batch_size, vocab size) (64, 1848)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QIkgh6I_wqC3","colab_type":"code","colab":{}},"source":["import tensorflow_addons as tfa\n","\n","input_shape = input_tensor.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yx3PoKDJpX48","colab_type":"code","colab":{}},"source":["initial_learning_rate = 0.1\n","\n","lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate,\n","    decay_steps=100,\n","    decay_rate=0.96,\n","    staircase=True)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n","\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n","\n","def loss_function(real, pred, input_shape, sequence_length=25):\n","\n","  #https://www.tensorflow.org/addons/api_docs/python/tfa/seq2seq/sequence_loss\n","  #return tfa.seq2seq.sequence_loss(pred, real, tf.ones([input_shape[0], sequence_length]))\n","\n","  mask = tf.math.logical_not(tf.math.equal(real, 0))\n","  loss_ = loss_object(real, pred)\n","\n","  mask = tf.cast(mask, dtype=loss_.dtype)\n","  loss_ *= mask\n","\n","  return tf.reduce_mean(loss_)\n","\n","#gradients = optimizer.compute_gradients(loss_error)\n","#clipped_gradients = [(tf.clip_by_value(grad_tensor, -5., 5.), grad_variable) for grad_tensor, grad_variable in gradients if grad_tensor is not None]\n","#optimizer_gradient_clipping = optimizer.apply_gradients(clipped_gradients)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IEQ6YCpAxu3p","colab_type":"code","colab":{}},"source":["import os\n","\n","checkpoint_dir = './training_checkpoints'\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n","checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n","                                 encoder=encoder,\n","                                 decoder=decoder)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tXRMByZrzIba","colab_type":"code","colab":{}},"source":["@tf.function\n","def train_step(inputs, targets, encoder_hidden):\n","  loss = 0\n","\n","  with tf.GradientTape() as tape:\n","    encoder_output, encoder_hidden = encoder(inputs, encoder_hidden)\n","\n","    decoder_hidden = encoder_hidden\n","\n","    decoder_input = tf.expand_dims([tokenizer.word_index['<start>']] * batch_size, 1)\n","\n","    # Teacher forcing - feeding the target as the next input\n","    for t in range(1, targets.shape[1]):\n","      # passing enc_output to the decoder\n","      predictions, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_output)\n","\n","      #print(targets[:, t].shape, predictions.shape, input_shape)\n","      loss += loss_function(targets[:, t], predictions, input_shape)\n","\n","      # using teacher forcing\n","      decoder_input = tf.expand_dims(targets[:, t], 1)\n","\n","  batch_loss = (loss / int(targets.shape[1]))\n","\n","  variables = encoder.trainable_variables + decoder.trainable_variables\n","\n","  gradients = tape.gradient(loss, variables)\n","  #gradients = optimizer.get_gradients(loss, variables)\n","  #clipped_gradients = [(tf.clip_by_value(grad_tensor, -5., 5.), grad_variable) for grad_tensor, grad_variable in gradients if grad_tensor is not None]\n","  #optimizer_gradient_clipping = optimizer.apply_gradients(clipped_gradients)\n","\n","  optimizer.apply_gradients(zip(gradients, variables))\n","\n","  return batch_loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e7Kc93QgKLOp","colab_type":"code","colab":{}},"source":["def evaluate(inputs, targets, encoder_hidden):\n","  \n","  loss = 0\n","  encoder_output, encoder_hidden = encoder(inputs, encoder_hidden)\n","  decoder_hidden = encoder_hidden\n","  \n","  decoder_input = tf.expand_dims([tokenizer.word_index['<start>']] * batch_size, 1)\n","  \n","  # Teacher forcing - feeding the target as the next input\n","  for t in range(1, targets.shape[1]):\n","    # passing enc_output to the decoder\n","    predictions, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_output)\n","    loss += loss_function(targets[:, t], predictions, input_shape)\n","    \n","    # using teacher forcing\n","    decoder_input = tf.expand_dims(targets[:, t], 1)\n","\n","  batch_loss = (loss / int(targets.shape[1]))\n","\n","  return batch_loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5yqVv_lqzutc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":218},"outputId":"6adfae52-49f8-4a38-f4f8-77172e5a4055","executionInfo":{"status":"ok","timestamp":1591544443214,"user_tz":-60,"elapsed":13086,"user":{"displayName":"Yong Joon Thoo","photoUrl":"","userId":"09654273073444808495"}}},"source":["EPOCHS = 2\n","batch_training_loss_check = 10\n","batch_validation_loss_check = steps_per_epoch // 2 - 1\n","\n","# elements for early stopping\n","list_validation_loss_error = []\n","early_stopping_check = 0\n","early_stopping_stop = 100\n","\n","for epoch in range(EPOCHS):\n","\n","  enc_hidden = encoder.initialize_hidden_state()\n","  total_train_loss = 0\n","\n","  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n","    start = time.time()\n","    batch_train_loss = train_step(inp, targ, enc_hidden)\n","    total_train_loss += batch_train_loss\n","    end = time.time()\n","    batch_time = end - start\n","\n","    if batch % batch_training_loss_check == 0:\n","      print('Epoch {}, Batch {}, Training Loss {:.3f}, Training Time on {} batches: {:.2f} s'.format(epoch + 1,\n","                                                   batch, batch_train_loss.numpy(), batch_training_loss_check, \n","                                                   batch_time*batch_training_loss_check))\n","      \n","    if batch % batch_validation_loss_check == 0 and batch > 0:\n","      total_valid_loss = 0\n","      start_val_time = time.time()\n","\n","      for (batch_val, (inp_val, targ_val)) in enumerate(dataset_val.take(len(input_tensor_val)//batch_size)):\n","        total_valid_loss += evaluate(inp_val, targ_val, enc_hidden)\n","\n","      ending_val_time = time.time()\n","      val_time = ending_val_time - start_val_time\n","\n","      average_validation_loss = total_valid_loss / (len(input_tensor_val) / batch_size)\n","      print(\"Avg Validation Loss Error: {:>6.3f}, Validation Time: {:.2f} s\".format(average_validation_loss, val_time))\n","\n","      # early stopping\n","      list_validation_loss_error.append(average_validation_loss_error)\n","      \n","      if average_validation_loss_error <= min(list_validation_loss_error):\n","        early_stopping_check = 0\n","        checkpoint.save(file_prefix = checkpoint_prefix)\n","      else:\n","        early_stopping_check += 1\n","        if early_stopping_check == early_stopping_stop:\n","          break\n","\n","  print('Epoch {}, Training Loss {:.3f}, Avg Validation Loss {:.3f}\\n'.format(epoch + 1,\n","                                      total_loss / steps_per_epoch, average_validation_loss))\n","  \n","  if early_stopping_check == early_stopping_stop:\n","    break"],"execution_count":123,"outputs":[{"output_type":"stream","text":["Epoch 1, Batch 0, Training Loss 1.699, Training Time on 10 batches: 3.55 s\n","Avg Validation Loss Error:  3.187, Validation Time: 1.17 s\n","Epoch 1, Batch 10, Training Loss 2.362, Training Time on 10 batches: 2.60 s\n","Avg Validation Loss Error:  3.081, Validation Time: 1.22 s\n","Epoch 1, Training Loss 1.811, Avg Validation Loss 3.081\n","\n","Epoch 2, Batch 0, Training Loss 1.857, Training Time on 10 batches: 2.48 s\n","Avg Validation Loss Error:  3.137, Validation Time: 1.21 s\n","Epoch 2, Batch 10, Training Loss 2.039, Training Time on 10 batches: 2.56 s\n","Avg Validation Loss Error:  3.056, Validation Time: 1.17 s\n","Epoch 2, Training Loss 1.811, Avg Validation Loss 3.056\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yEJ0Tf6ZbPGb","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}